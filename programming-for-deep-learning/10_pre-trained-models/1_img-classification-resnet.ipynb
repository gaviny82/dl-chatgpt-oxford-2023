{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aQWM3_JRMHfd"
      },
      "source": [
        "# Image Classification with ResNet50\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "b3381a5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Invalid requirement: '-'\n"
          ]
        }
      ],
      "source": [
        "# @title # Run the following cell to install the necessary libraries for this practical. { display-mode: \"form\" }\n",
        "# @markdown Don't worry about what's in this collapsed cell\n",
        "\n",
        "\n",
        "import urllib.request\n",
        "import os\n",
        "%pip install - q Pillow\n",
        "\n",
        "\n",
        "if not os.path.exists('data'):\n",
        "    os.mkdir('data')\n",
        "\n",
        "# Download duck.jpg\n",
        "if not os.path.exists('data/duck.jpg'):\n",
        "    print('Downloading duck.jpg...')\n",
        "    urllib.request.urlretrieve(\n",
        "        'https://s3-eu-west-1.amazonaws.com/aicore-portal-public-prod-307050600709/practicals_files/f0c57e1d-f903-496d-8561-002c618a1c7d/duck.jpg', 'data/duck.jpg')\n",
        "\n",
        "# Download imagenet_classes.txt\n",
        "if not os.path.exists('data/imagenet_classes.txt'):\n",
        "    print('Downloading imagenet_classes.txt...')\n",
        "    urllib.request.urlretrieve(\n",
        "        'https://s3-eu-west-1.amazonaws.com/aicore-portal-public-prod-307050600709/practicals_files/f0c57e1d-f903-496d-8561-002c618a1c7d/imagenet_classes.txt', 'data/imagenet_classes.txt')\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-N2wAB3tMHfg"
      },
      "source": [
        "Using a pre-trained image classifier is a quick and efficient way to classify images by content .It involves loading a pretrianed model that has been trained on a large dataset, and then using it to make predictions on new images. Models such as ResNet have already been trained to classify a large range of objects, and so the pretrained model can often be used without any additional training for basic classification tasks.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2zqBEEKyMHfh"
      },
      "source": [
        "## Import Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iTWAhc_cMHfh"
      },
      "outputs": [],
      "source": [
        "# import dependencies\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# utils\n",
        "def open_image(path: str, transform) -> torch.Tensor:\n",
        "    \"\"\"Get tensor of a local image and apply a transform\n",
        "\n",
        "    Args:\n",
        "        path (str): Path to image\n",
        "        transform (Any): Transform applied to an image tensor\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Transformed image tensor\n",
        "    \"\"\"\n",
        "    \n",
        "    img = Image.open(path).convert('RGB')\n",
        "    img_tensor = transform(img).unsqueeze(0)\n",
        "    \n",
        "    return img_tensor\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mh-QKWNSMHfh"
      },
      "source": [
        "## Image Transforms\n",
        "\n",
        "To use the pre-trained model, it is important to transform the image so as to present it to the model in a format which is compatible with the model's architecture, and also reflects the feature engineering used to train the model. For this we can use the `torchvision.transforms` module.\n",
        "\n",
        "The following codeblock uses the `transforms.compose` class to compose a sequence of transforms. Important considerations when using transforms for pre-trained images include ensuring that the image is of the correct size to match the input layer, and applying any transforms used on the original training set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xETTZHBPMHfi"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eumJIVbyMHfi"
      },
      "source": [
        "## Load an image from your directory structure\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TFDhiO8AMHfj"
      },
      "outputs": [],
      "source": [
        "img_tensor = open_image(\"data/duck.jpg\", transform)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gmn8HE5LMHfj"
      },
      "source": [
        "To make sense of the model's output, it is necessary to have a decoder - essentially a dictionary where the keys are the integer labels used by the classifier, and the values are the human-readable class nammes. The codeblock below loads in the classes as a list, with the keys implicit in the index position.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "d01dbOrNMHfj"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['goldfish',\n",
              " 'great white shark',\n",
              " 'tiger shark',\n",
              " 'hammerhead',\n",
              " 'electric ray',\n",
              " 'stingray',\n",
              " 'cock',\n",
              " 'hen',\n",
              " 'ostrich',\n",
              " 'brambling',\n",
              " 'goldfinch',\n",
              " 'house finch',\n",
              " 'junco',\n",
              " 'indigo bunting',\n",
              " 'robin',\n",
              " 'bulbul',\n",
              " 'jay',\n",
              " 'magpie',\n",
              " 'chickadee']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get imagenet classes\n",
        "with open(\"data/imagenet_classes.txt\", \"r\") as f:\n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "\n",
        "classes[1:20]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qKcIKSIYMHfk"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jinch\\.conda\\envs\\ML\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\jinch\\.conda\\envs\\ML\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output = model(img_tensor)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Z2Uu9HMMMHfk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction label:  tensor([285])\n",
            "Prediction category:  Egyptian cat\n"
          ]
        }
      ],
      "source": [
        "dummy, pred = torch.max(output, 1)\n",
        "print(\"Prediction label: \", pred)\n",
        "class_label = classes[pred]\n",
        "print(\"Prediction category: \", class_label)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ML",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "f5458f74cc04a2c0765be2b43bd75bd0f09091972ab65a3b08edb45fbf046640"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
