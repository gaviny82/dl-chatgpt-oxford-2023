{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DDv5I8nkEnJB"
      },
      "source": [
        "# End to End Regression Model Training in Pytorch\n",
        "\n",
        "Let's train a regression model from start to finish on some example data. For this practical we will use the Boston Housing dataset. The Boston Housing dataset is a widely used dataset for regression analysis and machine learning, consisting of 13 feature variables describing various aspects of residential homes in the Boston suburbs and a target variable indicating the median value of owner-occupied homes in $1000s. It was collected by the U.S Census Service in 1978 and has been used for benchmarking and evaluation of machine learning algorithms.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kNLrXE5WEnJE"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jinch\\.conda\\envs\\ML\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "# Run this cell to import the packages we need and load the dataset\n",
        "from sklearn.datasets import load_boston\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "boston_data = load_boston()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "g42NO2x_EnJF"
      },
      "source": [
        "Run the cell below to print the keys of the dataset dictionary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8PLN6cQPEnJF"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
              "        4.9800e+00],\n",
              "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
              "        9.1400e+00],\n",
              "       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
              "        4.0300e+00],\n",
              "       ...,\n",
              "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
              "        5.6400e+00],\n",
              "       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
              "        6.4800e+00],\n",
              "       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
              "        7.8800e+00]])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "boston_data['data']\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wYo0Vhp1EnJG"
      },
      "source": [
        "In the codeblock below, create a `pandas` dataframe called `df` from the array in the `data` field of the dictionary, assiging column names from the `feature_names` field.\n",
        "Then add a column called `Price` to the dataframe, consisting of the values in the `target` field.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xKCuL9xfEnJG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(506, 14)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
              "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
              "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
              "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
              "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
              "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
              "\n",
              "   PTRATIO       B  LSTAT  Price  \n",
              "0     15.3  396.90   4.98   24.0  \n",
              "1     17.8  396.90   9.14   21.6  \n",
              "2     17.8  392.83   4.03   34.7  \n",
              "3     18.7  394.63   2.94   33.4  \n",
              "4     18.7  396.90   5.33   36.2  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame(data=boston_data[\"data\"],\n",
        "                  columns=boston_data[\"feature_names\"])\n",
        "df[\"Price\"] = boston_data[\"target\"]\n",
        "\n",
        "print(df.shape)\n",
        "df.head()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FBveVZTZEnJG"
      },
      "source": [
        "Let's take a look at the data by running the cell below:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pykHfYNLEnJH"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.613524</td>\n",
              "      <td>11.363636</td>\n",
              "      <td>11.136779</td>\n",
              "      <td>0.069170</td>\n",
              "      <td>0.554695</td>\n",
              "      <td>6.284634</td>\n",
              "      <td>68.574901</td>\n",
              "      <td>3.795043</td>\n",
              "      <td>9.549407</td>\n",
              "      <td>408.237154</td>\n",
              "      <td>18.455534</td>\n",
              "      <td>356.674032</td>\n",
              "      <td>12.653063</td>\n",
              "      <td>22.532806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>8.601545</td>\n",
              "      <td>23.322453</td>\n",
              "      <td>6.860353</td>\n",
              "      <td>0.253994</td>\n",
              "      <td>0.115878</td>\n",
              "      <td>0.702617</td>\n",
              "      <td>28.148861</td>\n",
              "      <td>2.105710</td>\n",
              "      <td>8.707259</td>\n",
              "      <td>168.537116</td>\n",
              "      <td>2.164946</td>\n",
              "      <td>91.294864</td>\n",
              "      <td>7.141062</td>\n",
              "      <td>9.197104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.006320</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.460000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.385000</td>\n",
              "      <td>3.561000</td>\n",
              "      <td>2.900000</td>\n",
              "      <td>1.129600</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>187.000000</td>\n",
              "      <td>12.600000</td>\n",
              "      <td>0.320000</td>\n",
              "      <td>1.730000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.082045</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.190000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.449000</td>\n",
              "      <td>5.885500</td>\n",
              "      <td>45.025000</td>\n",
              "      <td>2.100175</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>279.000000</td>\n",
              "      <td>17.400000</td>\n",
              "      <td>375.377500</td>\n",
              "      <td>6.950000</td>\n",
              "      <td>17.025000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.256510</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.690000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.538000</td>\n",
              "      <td>6.208500</td>\n",
              "      <td>77.500000</td>\n",
              "      <td>3.207450</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>330.000000</td>\n",
              "      <td>19.050000</td>\n",
              "      <td>391.440000</td>\n",
              "      <td>11.360000</td>\n",
              "      <td>21.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.677083</td>\n",
              "      <td>12.500000</td>\n",
              "      <td>18.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.624000</td>\n",
              "      <td>6.623500</td>\n",
              "      <td>94.075000</td>\n",
              "      <td>5.188425</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>666.000000</td>\n",
              "      <td>20.200000</td>\n",
              "      <td>396.225000</td>\n",
              "      <td>16.955000</td>\n",
              "      <td>25.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>88.976200</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>27.740000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.871000</td>\n",
              "      <td>8.780000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>12.126500</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>711.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>396.900000</td>\n",
              "      <td>37.970000</td>\n",
              "      <td>50.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
              "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
              "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
              "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
              "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
              "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
              "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
              "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
              "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
              "\n",
              "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
              "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
              "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
              "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
              "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
              "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
              "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
              "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
              "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
              "\n",
              "            LSTAT       Price  \n",
              "count  506.000000  506.000000  \n",
              "mean    12.653063   22.532806  \n",
              "std      7.141062    9.197104  \n",
              "min      1.730000    5.000000  \n",
              "25%      6.950000   17.025000  \n",
              "50%     11.360000   21.200000  \n",
              "75%     16.955000   25.000000  \n",
              "max     37.970000   50.000000  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SwICXaAaEnJH"
      },
      "source": [
        "The data are quite diverse, with very different absolute value ranges for each feature. In order to give the features equivalent weight in the model, it is good practice to normalise the features data. Run the code block below to normalise the data:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RGyigYmwEnJI"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>5.060000e+02</td>\n",
              "      <td>506.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-1.123388e-16</td>\n",
              "      <td>4.037175e-17</td>\n",
              "      <td>3.089316e-16</td>\n",
              "      <td>-3.510587e-17</td>\n",
              "      <td>-2.527622e-16</td>\n",
              "      <td>-9.478584e-17</td>\n",
              "      <td>-1.685082e-16</td>\n",
              "      <td>-1.404235e-16</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.616939e-17</td>\n",
              "      <td>-4.212704e-16</td>\n",
              "      <td>-7.021173e-16</td>\n",
              "      <td>-3.229740e-16</td>\n",
              "      <td>22.532806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>9.197104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-4.193669e-01</td>\n",
              "      <td>-4.872402e-01</td>\n",
              "      <td>-1.556302e+00</td>\n",
              "      <td>-2.723291e-01</td>\n",
              "      <td>-1.464433e+00</td>\n",
              "      <td>-3.876413e+00</td>\n",
              "      <td>-2.333128e+00</td>\n",
              "      <td>-1.265817e+00</td>\n",
              "      <td>-0.981871</td>\n",
              "      <td>-1.312691e+00</td>\n",
              "      <td>-2.704703e+00</td>\n",
              "      <td>-3.903331e+00</td>\n",
              "      <td>-1.529613e+00</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-4.105633e-01</td>\n",
              "      <td>-4.872402e-01</td>\n",
              "      <td>-8.668328e-01</td>\n",
              "      <td>-2.723291e-01</td>\n",
              "      <td>-9.121262e-01</td>\n",
              "      <td>-5.680681e-01</td>\n",
              "      <td>-8.366200e-01</td>\n",
              "      <td>-8.048913e-01</td>\n",
              "      <td>-0.637331</td>\n",
              "      <td>-7.668172e-01</td>\n",
              "      <td>-4.875567e-01</td>\n",
              "      <td>2.048688e-01</td>\n",
              "      <td>-7.986296e-01</td>\n",
              "      <td>17.025000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-3.902803e-01</td>\n",
              "      <td>-4.872402e-01</td>\n",
              "      <td>-2.108898e-01</td>\n",
              "      <td>-2.723291e-01</td>\n",
              "      <td>-1.440749e-01</td>\n",
              "      <td>-1.083583e-01</td>\n",
              "      <td>3.170678e-01</td>\n",
              "      <td>-2.790473e-01</td>\n",
              "      <td>-0.522484</td>\n",
              "      <td>-4.642132e-01</td>\n",
              "      <td>2.745872e-01</td>\n",
              "      <td>3.808097e-01</td>\n",
              "      <td>-1.810744e-01</td>\n",
              "      <td>21.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.389247e-03</td>\n",
              "      <td>4.872402e-02</td>\n",
              "      <td>1.014995e+00</td>\n",
              "      <td>-2.723291e-01</td>\n",
              "      <td>5.980871e-01</td>\n",
              "      <td>4.822906e-01</td>\n",
              "      <td>9.059016e-01</td>\n",
              "      <td>6.617161e-01</td>\n",
              "      <td>1.659603</td>\n",
              "      <td>1.529413e+00</td>\n",
              "      <td>8.057784e-01</td>\n",
              "      <td>4.332223e-01</td>\n",
              "      <td>6.024226e-01</td>\n",
              "      <td>25.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.924110e+00</td>\n",
              "      <td>3.800473e+00</td>\n",
              "      <td>2.420170e+00</td>\n",
              "      <td>3.664771e+00</td>\n",
              "      <td>2.729645e+00</td>\n",
              "      <td>3.551530e+00</td>\n",
              "      <td>1.116390e+00</td>\n",
              "      <td>3.956602e+00</td>\n",
              "      <td>1.659603</td>\n",
              "      <td>1.796416e+00</td>\n",
              "      <td>1.637208e+00</td>\n",
              "      <td>4.406159e-01</td>\n",
              "      <td>3.545262e+00</td>\n",
              "      <td>50.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               CRIM            ZN         INDUS          CHAS           NOX  \\\n",
              "count  5.060000e+02  5.060000e+02  5.060000e+02  5.060000e+02  5.060000e+02   \n",
              "mean  -1.123388e-16  4.037175e-17  3.089316e-16 -3.510587e-17 -2.527622e-16   \n",
              "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
              "min   -4.193669e-01 -4.872402e-01 -1.556302e+00 -2.723291e-01 -1.464433e+00   \n",
              "25%   -4.105633e-01 -4.872402e-01 -8.668328e-01 -2.723291e-01 -9.121262e-01   \n",
              "50%   -3.902803e-01 -4.872402e-01 -2.108898e-01 -2.723291e-01 -1.440749e-01   \n",
              "75%    7.389247e-03  4.872402e-02  1.014995e+00 -2.723291e-01  5.980871e-01   \n",
              "max    9.924110e+00  3.800473e+00  2.420170e+00  3.664771e+00  2.729645e+00   \n",
              "\n",
              "                 RM           AGE           DIS         RAD           TAX  \\\n",
              "count  5.060000e+02  5.060000e+02  5.060000e+02  506.000000  5.060000e+02   \n",
              "mean  -9.478584e-17 -1.685082e-16 -1.404235e-16    0.000000  5.616939e-17   \n",
              "std    1.000000e+00  1.000000e+00  1.000000e+00    1.000000  1.000000e+00   \n",
              "min   -3.876413e+00 -2.333128e+00 -1.265817e+00   -0.981871 -1.312691e+00   \n",
              "25%   -5.680681e-01 -8.366200e-01 -8.048913e-01   -0.637331 -7.668172e-01   \n",
              "50%   -1.083583e-01  3.170678e-01 -2.790473e-01   -0.522484 -4.642132e-01   \n",
              "75%    4.822906e-01  9.059016e-01  6.617161e-01    1.659603  1.529413e+00   \n",
              "max    3.551530e+00  1.116390e+00  3.956602e+00    1.659603  1.796416e+00   \n",
              "\n",
              "            PTRATIO             B         LSTAT       Price  \n",
              "count  5.060000e+02  5.060000e+02  5.060000e+02  506.000000  \n",
              "mean  -4.212704e-16 -7.021173e-16 -3.229740e-16   22.532806  \n",
              "std    1.000000e+00  1.000000e+00  1.000000e+00    9.197104  \n",
              "min   -2.704703e+00 -3.903331e+00 -1.529613e+00    5.000000  \n",
              "25%   -4.875567e-01  2.048688e-01 -7.986296e-01   17.025000  \n",
              "50%    2.745872e-01  3.808097e-01 -1.810744e-01   21.200000  \n",
              "75%    8.057784e-01  4.332223e-01  6.024226e-01   25.000000  \n",
              "max    1.637208e+00  4.406159e-01  3.545262e+00   50.000000  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = df[df.columns[:-1]]\n",
        "data = data.apply(\n",
        "    lambda x: (x - x.mean()) / x.std()\n",
        ")\n",
        "\n",
        "data['Price'] = df.Price\n",
        "\n",
        "data.describe()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WAS747VAEnJI"
      },
      "source": [
        "We can see that the data are now arranged around a mean of approximately zero, with an SD of 1.\n",
        "\n",
        "We can now use this data to build a `Dataset` class - essentially a container that stores the data, along with a set of inbuilt functions (methods) which allow us to pass the data to our model in a format that it can use. You don't need to worry too much about the details of the `Dataset` class at this stage, but you can read a brief description of its structure below.\n",
        "\n",
        "There are three key methods in a Pytorch dataset:\n",
        "\n",
        "- The first is the class constructor, which is a method that every Python class has. It tells the python interpreter what to do when it makes an instance of the class.\n",
        "\n",
        "- Second, we need a method called `__getitem__`. This method defines what happens when we ask the dataset for a single example datapoint - ie. a set of features and a label.\n",
        "\n",
        "- Finally we have the `__len__` method. This describes what to do when we call python's `len()` method on the dataset, and returns the number of samples in the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yWL8ERdsEnJI"
      },
      "outputs": [],
      "source": [
        "class BostonDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.x = data.drop('Price', axis=1).to_numpy()\n",
        "        self.y = data['Price'].to_numpy()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        features = torch.tensor(\n",
        "            self.x[idx, :], dtype=torch.float32).unsqueeze(0)\n",
        "        label = torch.tensor(self.y[idx], dtype=torch.float32)\n",
        "        return features, label\n",
        "\n",
        "\n",
        "dataset = BostonDataset()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XwvX10hREnJJ"
      },
      "source": [
        "You can now get a single sample of the data by indexing. Add some code to the cell below to print the shape of the features and the label from a single sample of the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nbOlrbj0EnJJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "features shape: torch.Size([1, 13])\n",
            "label shape: torch.Size([])\n"
          ]
        }
      ],
      "source": [
        "features, label = dataset[1]\n",
        "print(f\"features shape: {features.shape}\")\n",
        "print(f\"label shape: {label.shape}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0BrtAuenEnJJ"
      },
      "source": [
        "We next define a data loader. The `dataloader` is a tool for collating a batch of samples from the dataset, and passing it to the model. Look online at the docs for `torch.utils.data.DataLoader` and see if you can work out how to get the dataloader to give us an example batch of data, and print the shape of the batch of features and the batch of labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-euz-32JEnJJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "features shape: torch.Size([8, 1, 13])\n",
            "label shape: torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "data_loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=True)\n",
        "# Add code to get the next iteration of the dataloader, and print the shape of the labels and features\n",
        "\n",
        "\n",
        "features, label = next(iter(data_loader))\n",
        "print(f\"features shape: {features.shape}\")\n",
        "print(f\"label shape: {label.shape}\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "i_hjVDwfEnJK"
      },
      "source": [
        "Now that we have defined how to pass the data to our model, we can build the model itself. You don't need to worry about all the details of how the model is constructed at this stage, just note that it is built from an alternating sequence of linear and nonlinear (`ReLu`) layers. Also note that it contains an inbuilt function (known as a `method`) called `forward`. The `forward` method defines what happens when we pass the data to the model during the forward pass, and all the detail is handled under the surface by `Pytorch` !\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "a_melNz3EnJK"
      },
      "outputs": [],
      "source": [
        "class RegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RegressionModel, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(13, 13),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(13, 13),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(13, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oCOJsLVlEnJK"
      },
      "source": [
        "Next we set things up ready for training. The definition in the previous code block is called a `class`, and is a general description of the model, whereas the variable called `model` below is an instance of that class, a single example of it.\n",
        "\n",
        "The `criterion` is the function we use to calculate the loss between the predictions and the labels, in this case we are doing regression so we use mean-squared-error (`MSE`).\n",
        "\n",
        "Finally we need an `optimiser`, that's the function that determines how to update the model's connection weights based on the gradients.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VjFPFMecEnJK"
      },
      "outputs": [],
      "source": [
        "model = RegressionModel()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pqz8k5nMEnJL"
      },
      "source": [
        "The last step is to construct the training loop. The cell below contains a basic outline for the training loop. Fill in the python code to make it work correctly, per the comments.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IjzJyYEnEnJL"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jinch\\.conda\\envs\\ML\\lib\\site-packages\\torch\\nn\\modules\\loss.py:530: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "c:\\Users\\jinch\\.conda\\envs\\ML\\lib\\site-packages\\torch\\nn\\modules\\loss.py:530: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/100, Loss: 532.5421\n",
            "Epoch: 2/100, Loss: 500.2319\n",
            "Epoch: 3/100, Loss: 355.4820\n",
            "Epoch: 4/100, Loss: 197.6903\n",
            "Epoch: 5/100, Loss: 440.4743\n",
            "Epoch: 6/100, Loss: 235.7080\n",
            "Epoch: 7/100, Loss: 1131.8906\n",
            "Epoch: 8/100, Loss: 146.7092\n",
            "Epoch: 9/100, Loss: 380.9966\n",
            "Epoch: 10/100, Loss: 152.0188\n",
            "Epoch: 11/100, Loss: 377.4846\n",
            "Epoch: 12/100, Loss: 232.3211\n",
            "Epoch: 13/100, Loss: 81.7835\n",
            "Epoch: 14/100, Loss: 125.0699\n",
            "Epoch: 15/100, Loss: 196.2721\n",
            "Epoch: 16/100, Loss: 1.2955\n",
            "Epoch: 17/100, Loss: 107.8223\n",
            "Epoch: 18/100, Loss: 14.7951\n",
            "Epoch: 19/100, Loss: 26.4853\n",
            "Epoch: 20/100, Loss: 128.3333\n",
            "Epoch: 21/100, Loss: 208.8690\n",
            "Epoch: 22/100, Loss: 172.8024\n",
            "Epoch: 23/100, Loss: 102.3557\n",
            "Epoch: 24/100, Loss: 15.9141\n",
            "Epoch: 25/100, Loss: 125.0678\n",
            "Epoch: 26/100, Loss: 17.6113\n",
            "Epoch: 27/100, Loss: 1.5765\n",
            "Epoch: 28/100, Loss: 158.5664\n",
            "Epoch: 29/100, Loss: 6.1626\n",
            "Epoch: 30/100, Loss: 260.0838\n",
            "Epoch: 31/100, Loss: 8.6416\n",
            "Epoch: 32/100, Loss: 319.7652\n",
            "Epoch: 33/100, Loss: 28.3402\n",
            "Epoch: 34/100, Loss: 136.3004\n",
            "Epoch: 35/100, Loss: 20.1616\n",
            "Epoch: 36/100, Loss: 205.4057\n",
            "Epoch: 37/100, Loss: 5.7525\n",
            "Epoch: 38/100, Loss: 0.7307\n",
            "Epoch: 39/100, Loss: 366.1218\n",
            "Epoch: 40/100, Loss: 40.6734\n",
            "Epoch: 41/100, Loss: 373.1438\n",
            "Epoch: 42/100, Loss: 0.7096\n",
            "Epoch: 43/100, Loss: 109.8212\n",
            "Epoch: 44/100, Loss: 26.1542\n",
            "Epoch: 45/100, Loss: 2.6221\n",
            "Epoch: 46/100, Loss: 111.6692\n",
            "Epoch: 47/100, Loss: 63.2884\n",
            "Epoch: 48/100, Loss: 12.1590\n",
            "Epoch: 49/100, Loss: 97.3786\n",
            "Epoch: 50/100, Loss: 23.1725\n",
            "Epoch: 51/100, Loss: 13.8081\n",
            "Epoch: 52/100, Loss: 2.9661\n",
            "Epoch: 53/100, Loss: 67.0036\n",
            "Epoch: 54/100, Loss: 1.8321\n",
            "Epoch: 55/100, Loss: 8.6828\n",
            "Epoch: 56/100, Loss: 49.7766\n",
            "Epoch: 57/100, Loss: 7.3108\n",
            "Epoch: 58/100, Loss: 19.5659\n",
            "Epoch: 59/100, Loss: 13.1099\n",
            "Epoch: 60/100, Loss: 392.8190\n",
            "Epoch: 61/100, Loss: 95.6426\n",
            "Epoch: 62/100, Loss: 45.4150\n",
            "Epoch: 63/100, Loss: 30.8051\n",
            "Epoch: 64/100, Loss: 365.9859\n",
            "Epoch: 65/100, Loss: 20.8241\n",
            "Epoch: 66/100, Loss: 2.9460\n",
            "Epoch: 67/100, Loss: 62.5453\n",
            "Epoch: 68/100, Loss: 59.3051\n",
            "Epoch: 69/100, Loss: 42.0338\n",
            "Epoch: 70/100, Loss: 48.9204\n",
            "Epoch: 71/100, Loss: 31.4281\n",
            "Epoch: 72/100, Loss: 159.2739\n",
            "Epoch: 73/100, Loss: 7.3959\n",
            "Epoch: 74/100, Loss: 11.5337\n",
            "Epoch: 75/100, Loss: 67.7616\n",
            "Epoch: 76/100, Loss: 2.5024\n",
            "Epoch: 77/100, Loss: 199.3235\n",
            "Epoch: 78/100, Loss: 42.5261\n",
            "Epoch: 79/100, Loss: 15.5636\n",
            "Epoch: 80/100, Loss: 8.6650\n",
            "Epoch: 81/100, Loss: 93.5387\n",
            "Epoch: 82/100, Loss: 21.4719\n",
            "Epoch: 83/100, Loss: 280.1030\n",
            "Epoch: 84/100, Loss: 8.0893\n",
            "Epoch: 85/100, Loss: 222.9805\n",
            "Epoch: 86/100, Loss: 18.1769\n",
            "Epoch: 87/100, Loss: 36.0565\n",
            "Epoch: 88/100, Loss: 16.9406\n",
            "Epoch: 89/100, Loss: 20.9324\n",
            "Epoch: 90/100, Loss: 97.5473\n",
            "Epoch: 91/100, Loss: 73.0163\n",
            "Epoch: 92/100, Loss: 18.0161\n",
            "Epoch: 93/100, Loss: 93.6508\n",
            "Epoch: 94/100, Loss: 5.5415\n",
            "Epoch: 95/100, Loss: 62.7510\n",
            "Epoch: 96/100, Loss: 28.6012\n",
            "Epoch: 97/100, Loss: 45.2945\n",
            "Epoch: 98/100, Loss: 6.5706\n",
            "Epoch: 99/100, Loss: 6.0791\n",
            "Epoch: 100/100, Loss: 32.7332\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(800)\n",
        "\n",
        "epoch_idx = 0\n",
        "losses = []\n",
        "epochs = []\n",
        "\n",
        "for epoch in range(100):\n",
        "    for i, (inputs, targets) in enumerate(data_loader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch: {epoch + 1}/100, Loss: {loss.item():.4f}')\n",
        "    losses.append(loss.item())\n",
        "    epochs.append(epoch_idx)\n",
        "\n",
        "    epoch_idx += 1\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PLaSvwMQEnJL"
      },
      "source": [
        "Now let's plot our loss curve. Use the matplotlib library to make a scattergraph of your list of loss values (y-axis) against epoch number (x-axis). What can you say about the training? Has the model converged?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Q7fuedrAEnJL"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x2401542b700>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(epochs, losses)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ML",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "f5458f74cc04a2c0765be2b43bd75bd0f09091972ab65a3b08edb45fbf046640"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
