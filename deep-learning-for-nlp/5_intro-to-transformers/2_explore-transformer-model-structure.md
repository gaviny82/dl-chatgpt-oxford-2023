# Practical

1. If you don't already have one, create a virtual environment and install Huggingface `transformers` library.
2. Download GPT, GPT2, BERT base models.
3. Find out how many layers of transformer blocks each model has.
4. Once you are finished, learn to delete any cached models from your hard disk. You can use this [link](https://huggingface.co/docs/datasets/cache) to learn how!
